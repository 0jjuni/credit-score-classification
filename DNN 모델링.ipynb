{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T02:47:20.567496Z",
     "start_time": "2024-09-13T02:47:17.522104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "df = pd.read_csv('scaled_train.csv')\n",
    "\n",
    "categorical_columns = ['Occupation', 'Type_of_Loan', 'Credit_Mix', 'Payment_of_Min_Amount', 'Payment_Behaviour']\n",
    "numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns"
   ],
   "id": "c8285265ee35e23e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T02:47:28.841472Z",
     "start_time": "2024-09-13T02:47:28.701993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Label Encoding (범주형 변수만)\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# 타겟 변수 Encoding\n",
    "target_encoder = LabelEncoder()\n",
    "df['Credit_Score'] = target_encoder.fit_transform(df['Credit_Score'])\n",
    "\n",
    "# 표준화하지 않는 범주형 변수와 이미 스케일링된 K-means 컬럼을 분리\n",
    "X_categorical = df[categorical_columns].values  # 범주형 변수 (표준화 X)\n",
    "X_numerical = df[numerical_columns].values  # 수치형 변수 (표준화 필요)\n",
    "X_kmeans = df[['kmeans']].values  # 이미 클러스터링된 결과 (표준화 필요 X)\n",
    "\n",
    "# 수치형 변수만 표준화\n",
    "scaler = StandardScaler()\n",
    "X_numerical_scaled = scaler.fit_transform(X_numerical)\n",
    "\n",
    "# 범주형 + 수치형 + kmeans 결과 병합\n",
    "X = np.hstack((X_categorical, X_numerical_scaled, X_kmeans))\n",
    "\n",
    "# 타겟 변수\n",
    "y = df['Credit_Score'].values\n",
    "\n",
    "# 훈련/테스트 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)"
   ],
   "id": "7a83b8ff34151cba",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SMOTENC 적용",
   "id": "609caca8492f58b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T02:47:34.245475Z",
     "start_time": "2024-09-13T02:47:34.242257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 범주형 변수가 먼저 포함되어 있고, 마지막에 k-means 결과가 있으므로 범주형 인덱스를 추출\n",
    "num_categorical_columns = len(categorical_columns)\n",
    "kmeans_index = X.shape[1] - 1  # k-means가 마지막 열이므로 그 인덱스를 구함\n",
    "\n",
    "# 범주형 변수 인덱스 + k-means 인덱스\n",
    "categorical_indices = list(range(num_categorical_columns)) + [kmeans_index]\n"
   ],
   "id": "87a081ccb288ec36",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T02:48:33.065474Z",
     "start_time": "2024-09-13T02:47:37.046732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "print(Counter(y_train))\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "# 범주형 변수가 있는 경우 SMOTE-NC 적용\n",
    "smote_nc = SMOTENC(random_state=42, categorical_features=categorical_indices)  # 범주형 변수의 인덱스를 지정\n",
    "X_train_resampled, y_train_resampled = smote_nc.fit_resample(X_train, y_train)\n",
    "\n",
    "# SMOTE-NC 적용 후 분포 확인\n",
    "print(Counter(y_train_resampled))\n"
   ],
   "id": "5d3426eab70ffb7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 42539, 1: 23199, 0: 14262})\n",
      "Counter({2: 42539, 1: 42539, 0: 42539})\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T02:50:31.988729Z",
     "start_time": "2024-09-13T02:50:31.967587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CreditScoreDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "train_dataset = CreditScoreDataset(X_train_resampled, y_train_resampled)\n",
    "test_dataset = CreditScoreDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)"
   ],
   "id": "97d5137cc339758",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vlTQLbfpuIuk",
    "outputId": "705c2ba8-288c-4785-a8dd-ee1e75cfba90",
    "ExecuteTime": {
     "end_time": "2024-09-13T02:58:51.180547Z",
     "start_time": "2024-09-13T02:50:41.566540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        # 레이어 7개 구성\n",
    "        self.layer1 = nn.Linear(input_size, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.layer2 = nn.Linear(256, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.layer3 = nn.Linear(512, 1024)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.layer4 = nn.Linear(1024, 512)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.layer5 = nn.Linear(512, 256)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.layer6 = nn.Linear(256, 128)\n",
    "        self.bn6 = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.output_layer = nn.Linear(128, 3)  # 출력층\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # He 초기화 적용\n",
    "        for layer in [self.layer1, self.layer2, self.layer3, self.layer4, self.layer5, self.layer6, self.output_layer]:\n",
    "            nn.init.kaiming_normal_(layer.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.layer1(x)))\n",
    "        x = self.relu(self.dropout1(self.bn2(self.layer2(x))))\n",
    "        x = self.relu(self.dropout2(self.bn3(self.layer3(x))))\n",
    "        x = self.relu(self.dropout3(self.bn4(self.layer4(x))))\n",
    "        x = self.relu(self.bn5(self.layer5(x)))\n",
    "        x = self.relu(self.bn6(self.layer6(x)))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# 모델 초기화 및 학습 준비\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size = X_train_resampled.shape[1]\n",
    "model = MLP(input_size).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Adam 옵티마이저 사용\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.003, weight_decay=0.002)\n",
    "\n",
    "# 학습률 스케줄러 추가: 5 에폭마다 학습률을 40%로 감소\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.8)\n",
    "\n",
    "# Early Stopping 변수 초기화\n",
    "best_val_accuracy = 0\n",
    "early_stop_counter = 0\n",
    "patience = 60  # 에폭 동안 개선되지 않으면 중지\n",
    "\n",
    "epochs = 900\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_train += targets.size(0)\n",
    "        correct_train += (predicted == targets).sum().item()\n",
    "\n",
    "    # 학습률 스케줄러 업데이트\n",
    "    scheduler.step()\n",
    "\n",
    "    # 평가 모드\n",
    "    model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += targets.size(0)\n",
    "            correct_val += (predicted == targets).sum().item()\n",
    "\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}, '\n",
    "          f'학습 정확도: {train_accuracy:.2f}%, 평가 정확도: {val_accuracy:.2f}%')\n",
    "\n",
    "    # Early Stopping 조건 체크\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_train_accuracy = train_accuracy\n",
    "        best_epoch = epoch + 1  # 가장 좋은 성능을 보인 에폭 저장\n",
    "        early_stop_counter = 0  # 평가 정확도가 개선되면 카운터 초기화\n",
    "    else:\n",
    "        early_stop_counter += 1  # 개선되지 않으면 카운터 증가\n",
    "\n",
    "    if early_stop_counter >= patience:\n",
    "        print(\"Early stopping triggered!\")\n",
    "        break  # 학습 중지\n",
    "\n",
    "# Early Stopping 후 가장 좋았던 모델의 성능 출력\n",
    "print(f'Early Stopping triggered at epoch {best_epoch}, '\n",
    "      f'Best 평가 정확도: {best_val_accuracy:.2f}%, '\n",
    "      f'Best 학습 정확도: {best_train_accuracy:.2f}%')\n"
   ],
   "id": "2b4aad9eda503f5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/900], Loss: 0.8616, 학습 정확도: 61.74%, 평가 정확도: 54.53%\n",
      "Epoch [2/900], Loss: 0.7818, 학습 정확도: 67.72%, 평가 정확도: 59.40%\n",
      "Epoch [3/900], Loss: 0.7655, 학습 정확도: 68.85%, 평가 정확도: 39.28%\n",
      "Epoch [4/900], Loss: 0.7603, 학습 정확도: 69.19%, 평가 정확도: 62.96%\n",
      "Epoch [5/900], Loss: 0.7376, 학습 정확도: 70.67%, 평가 정확도: 65.14%\n",
      "Epoch [6/900], Loss: 0.7303, 학습 정확도: 70.99%, 평가 정확도: 48.74%\n",
      "Epoch [7/900], Loss: 0.7123, 학습 정확도: 71.46%, 평가 정확도: 60.40%\n",
      "Epoch [8/900], Loss: 0.6965, 학습 정확도: 71.52%, 평가 정확도: 57.93%\n",
      "Epoch [9/900], Loss: 0.6834, 학습 정확도: 72.03%, 평가 정확도: 67.08%\n",
      "Epoch [10/900], Loss: 0.6790, 학습 정확도: 72.21%, 평가 정확도: 64.78%\n",
      "Epoch [11/900], Loss: 0.6756, 학습 정확도: 72.26%, 평가 정확도: 62.90%\n",
      "Epoch [12/900], Loss: 0.6720, 학습 정확도: 72.45%, 평가 정확도: 64.53%\n",
      "Epoch [13/900], Loss: 0.6695, 학습 정확도: 72.44%, 평가 정확도: 50.98%\n",
      "Epoch [14/900], Loss: 0.6661, 학습 정확도: 72.54%, 평가 정확도: 60.91%\n",
      "Epoch [15/900], Loss: 0.6645, 학습 정확도: 72.63%, 평가 정확도: 57.41%\n",
      "Epoch [16/900], Loss: 0.6610, 학습 정확도: 72.72%, 평가 정확도: 49.83%\n",
      "Epoch [17/900], Loss: 0.6593, 학습 정확도: 72.84%, 평가 정확도: 66.36%\n",
      "Epoch [18/900], Loss: 0.6606, 학습 정확도: 72.73%, 평가 정확도: 56.26%\n",
      "Epoch [19/900], Loss: 0.6562, 학습 정확도: 72.85%, 평가 정확도: 61.67%\n",
      "Epoch [20/900], Loss: 0.6556, 학습 정확도: 72.92%, 평가 정확도: 65.22%\n",
      "Epoch [21/900], Loss: 0.6531, 학습 정확도: 73.08%, 평가 정확도: 61.52%\n",
      "Epoch [22/900], Loss: 0.6508, 학습 정확도: 73.04%, 평가 정확도: 57.22%\n",
      "Epoch [23/900], Loss: 0.6491, 학습 정확도: 73.12%, 평가 정확도: 64.90%\n",
      "Epoch [24/900], Loss: 0.6472, 학습 정확도: 73.24%, 평가 정확도: 63.60%\n",
      "Epoch [25/900], Loss: 0.6464, 학습 정확도: 73.17%, 평가 정확도: 59.76%\n",
      "Epoch [26/900], Loss: 0.6420, 학습 정확도: 73.43%, 평가 정확도: 59.17%\n",
      "Epoch [27/900], Loss: 0.6413, 학습 정확도: 73.41%, 평가 정확도: 65.56%\n",
      "Epoch [28/900], Loss: 0.6395, 학습 정확도: 73.41%, 평가 정확도: 65.71%\n",
      "Epoch [29/900], Loss: 0.6385, 학습 정확도: 73.53%, 평가 정확도: 65.31%\n",
      "Epoch [30/900], Loss: 0.6368, 학습 정확도: 73.53%, 평가 정확도: 62.20%\n",
      "Epoch [31/900], Loss: 0.6311, 학습 정확도: 73.69%, 평가 정확도: 54.09%\n",
      "Epoch [32/900], Loss: 0.6284, 학습 정확도: 73.78%, 평가 정확도: 63.72%\n",
      "Epoch [33/900], Loss: 0.6277, 학습 정확도: 73.89%, 평가 정확도: 57.09%\n",
      "Epoch [34/900], Loss: 0.6245, 학습 정확도: 73.90%, 평가 정확도: 65.70%\n",
      "Epoch [35/900], Loss: 0.6221, 학습 정확도: 74.02%, 평가 정확도: 57.74%\n",
      "Epoch [36/900], Loss: 0.6207, 학습 정확도: 74.11%, 평가 정확도: 56.89%\n",
      "Epoch [37/900], Loss: 0.6183, 학습 정확도: 74.19%, 평가 정확도: 66.00%\n",
      "Epoch [38/900], Loss: 0.6161, 학습 정확도: 74.26%, 평가 정확도: 62.63%\n",
      "Epoch [39/900], Loss: 0.6125, 학습 정확도: 74.36%, 평가 정확도: 63.80%\n",
      "Epoch [40/900], Loss: 0.6124, 학습 정확도: 74.38%, 평가 정확도: 65.24%\n",
      "Epoch [41/900], Loss: 0.6100, 학습 정확도: 74.45%, 평가 정확도: 66.56%\n",
      "Epoch [42/900], Loss: 0.6061, 학습 정확도: 74.69%, 평가 정확도: 65.50%\n",
      "Epoch [43/900], Loss: 0.6035, 학습 정확도: 74.73%, 평가 정확도: 64.47%\n",
      "Epoch [44/900], Loss: 0.6014, 학습 정확도: 74.87%, 평가 정확도: 67.34%\n",
      "Epoch [45/900], Loss: 0.5974, 학습 정확도: 75.00%, 평가 정확도: 62.57%\n",
      "Epoch [46/900], Loss: 0.5907, 학습 정확도: 75.30%, 평가 정확도: 64.26%\n",
      "Epoch [47/900], Loss: 0.5859, 학습 정확도: 75.56%, 평가 정확도: 64.28%\n",
      "Epoch [48/900], Loss: 0.5829, 학습 정확도: 75.60%, 평가 정확도: 55.23%\n",
      "Epoch [49/900], Loss: 0.5784, 학습 정확도: 75.92%, 평가 정확도: 61.01%\n",
      "Epoch [50/900], Loss: 0.5750, 학습 정확도: 76.07%, 평가 정확도: 66.89%\n",
      "Epoch [51/900], Loss: 0.5699, 학습 정확도: 76.20%, 평가 정확도: 52.95%\n",
      "Epoch [52/900], Loss: 0.5675, 학습 정확도: 76.38%, 평가 정확도: 60.84%\n",
      "Epoch [53/900], Loss: 0.5606, 학습 정확도: 76.69%, 평가 정확도: 59.15%\n",
      "Epoch [54/900], Loss: 0.5574, 학습 정확도: 76.89%, 평가 정확도: 53.05%\n",
      "Epoch [55/900], Loss: 0.5529, 학습 정확도: 77.14%, 평가 정확도: 62.87%\n",
      "Epoch [56/900], Loss: 0.5466, 학습 정확도: 77.43%, 평가 정확도: 57.35%\n",
      "Epoch [57/900], Loss: 0.5421, 학습 정확도: 77.61%, 평가 정확도: 66.52%\n",
      "Epoch [58/900], Loss: 0.5361, 학습 정확도: 77.93%, 평가 정확도: 66.11%\n",
      "Epoch [59/900], Loss: 0.5298, 학습 정확도: 78.21%, 평가 정확도: 62.89%\n",
      "Epoch [60/900], Loss: 0.5256, 학습 정확도: 78.32%, 평가 정확도: 63.51%\n",
      "Epoch [61/900], Loss: 0.5152, 학습 정확도: 78.92%, 평가 정확도: 67.50%\n",
      "Epoch [62/900], Loss: 0.5100, 학습 정확도: 79.19%, 평가 정확도: 66.17%\n",
      "Epoch [63/900], Loss: 0.5021, 학습 정확도: 79.49%, 평가 정확도: 69.68%\n",
      "Epoch [64/900], Loss: 0.4982, 학습 정확도: 79.73%, 평가 정확도: 68.22%\n",
      "Epoch [65/900], Loss: 0.4926, 학습 정확도: 80.02%, 평가 정확도: 65.36%\n",
      "Epoch [66/900], Loss: 0.4863, 학습 정확도: 80.19%, 평가 정확도: 64.36%\n",
      "Epoch [67/900], Loss: 0.4835, 학습 정확도: 80.44%, 평가 정확도: 68.54%\n",
      "Epoch [68/900], Loss: 0.4764, 학습 정확도: 80.73%, 평가 정확도: 63.62%\n",
      "Epoch [69/900], Loss: 0.4714, 학습 정확도: 81.00%, 평가 정확도: 64.15%\n",
      "Epoch [70/900], Loss: 0.4671, 학습 정확도: 81.16%, 평가 정확도: 68.01%\n",
      "Epoch [71/900], Loss: 0.4624, 학습 정확도: 81.41%, 평가 정확도: 69.36%\n",
      "Epoch [72/900], Loss: 0.4561, 학습 정확도: 81.71%, 평가 정확도: 68.52%\n",
      "Epoch [73/900], Loss: 0.4540, 학습 정확도: 81.73%, 평가 정확도: 69.89%\n",
      "Epoch [74/900], Loss: 0.4476, 학습 정확도: 82.09%, 평가 정확도: 70.39%\n",
      "Epoch [75/900], Loss: 0.4425, 학습 정확도: 82.22%, 평가 정확도: 70.16%\n",
      "Epoch [76/900], Loss: 0.4347, 학습 정확도: 82.57%, 평가 정확도: 69.69%\n",
      "Epoch [77/900], Loss: 0.4289, 학습 정확도: 82.96%, 평가 정확도: 61.42%\n",
      "Epoch [78/900], Loss: 0.4237, 학습 정확도: 83.17%, 평가 정확도: 69.73%\n",
      "Epoch [79/900], Loss: 0.4185, 학습 정확도: 83.41%, 평가 정확도: 73.82%\n",
      "Epoch [80/900], Loss: 0.4168, 학습 정확도: 83.48%, 평가 정확도: 67.33%\n",
      "Epoch [81/900], Loss: 0.4125, 학습 정확도: 83.61%, 평가 정확도: 72.53%\n",
      "Epoch [82/900], Loss: 0.4080, 학습 정확도: 83.83%, 평가 정확도: 66.47%\n",
      "Epoch [83/900], Loss: 0.4056, 학습 정확도: 84.01%, 평가 정확도: 70.81%\n",
      "Epoch [84/900], Loss: 0.4023, 학습 정확도: 84.22%, 평가 정확도: 72.49%\n",
      "Epoch [85/900], Loss: 0.3965, 학습 정확도: 84.34%, 평가 정확도: 72.61%\n",
      "Epoch [86/900], Loss: 0.3947, 학습 정확도: 84.43%, 평가 정확도: 68.50%\n",
      "Epoch [87/900], Loss: 0.3919, 학습 정확도: 84.69%, 평가 정확도: 73.39%\n",
      "Epoch [88/900], Loss: 0.3877, 학습 정확도: 84.83%, 평가 정확도: 60.47%\n",
      "Epoch [89/900], Loss: 0.3863, 학습 정확도: 84.83%, 평가 정확도: 72.41%\n",
      "Epoch [90/900], Loss: 0.3823, 학습 정확도: 85.07%, 평가 정확도: 70.32%\n",
      "Epoch [91/900], Loss: 0.3741, 학습 정확도: 85.31%, 평가 정확도: 69.71%\n",
      "Epoch [92/900], Loss: 0.3679, 학습 정확도: 85.66%, 평가 정확도: 75.89%\n",
      "Epoch [93/900], Loss: 0.3665, 학습 정확도: 85.65%, 평가 정확도: 74.80%\n",
      "Epoch [94/900], Loss: 0.3625, 학습 정확도: 85.89%, 평가 정확도: 71.42%\n",
      "Epoch [95/900], Loss: 0.3602, 학습 정확도: 86.06%, 평가 정확도: 75.15%\n",
      "Epoch [96/900], Loss: 0.3592, 학습 정확도: 86.14%, 평가 정확도: 72.83%\n",
      "Epoch [97/900], Loss: 0.3554, 학습 정확도: 86.15%, 평가 정확도: 71.98%\n",
      "Epoch [98/900], Loss: 0.3555, 학습 정확도: 86.19%, 평가 정확도: 72.19%\n",
      "Epoch [99/900], Loss: 0.3514, 학습 정확도: 86.46%, 평가 정확도: 73.33%\n",
      "Epoch [100/900], Loss: 0.3499, 학습 정확도: 86.44%, 평가 정확도: 74.42%\n",
      "Epoch [101/900], Loss: 0.3462, 학습 정확도: 86.56%, 평가 정확도: 66.39%\n",
      "Epoch [102/900], Loss: 0.3440, 학습 정확도: 86.69%, 평가 정확도: 73.54%\n",
      "Epoch [103/900], Loss: 0.3431, 학습 정확도: 86.69%, 평가 정확도: 69.06%\n",
      "Epoch [104/900], Loss: 0.3408, 학습 정확도: 86.85%, 평가 정확도: 67.36%\n",
      "Epoch [105/900], Loss: 0.3382, 학습 정확도: 86.96%, 평가 정확도: 68.00%\n",
      "Epoch [106/900], Loss: 0.3316, 학습 정확도: 87.28%, 평가 정확도: 76.59%\n",
      "Epoch [107/900], Loss: 0.3298, 학습 정확도: 87.29%, 평가 정확도: 71.16%\n",
      "Epoch [108/900], Loss: 0.3274, 학습 정확도: 87.52%, 평가 정확도: 74.83%\n",
      "Epoch [109/900], Loss: 0.3251, 학습 정확도: 87.42%, 평가 정확도: 70.81%\n",
      "Epoch [110/900], Loss: 0.3212, 학습 정확도: 87.64%, 평가 정확도: 76.67%\n",
      "Epoch [111/900], Loss: 0.3242, 학습 정확도: 87.54%, 평가 정확도: 74.00%\n",
      "Epoch [112/900], Loss: 0.3170, 학습 정확도: 87.87%, 평가 정확도: 76.71%\n",
      "Epoch [113/900], Loss: 0.3179, 학습 정확도: 87.76%, 평가 정확도: 79.14%\n",
      "Epoch [114/900], Loss: 0.3173, 학습 정확도: 87.83%, 평가 정확도: 76.64%\n",
      "Epoch [115/900], Loss: 0.3158, 학습 정확도: 87.93%, 평가 정확도: 71.81%\n",
      "Epoch [116/900], Loss: 0.3132, 학습 정확도: 88.02%, 평가 정확도: 77.64%\n",
      "Epoch [117/900], Loss: 0.3096, 학습 정확도: 88.10%, 평가 정확도: 77.53%\n",
      "Epoch [118/900], Loss: 0.3116, 학습 정확도: 88.01%, 평가 정확도: 66.39%\n",
      "Epoch [119/900], Loss: 0.3080, 학습 정확도: 88.35%, 평가 정확도: 70.99%\n",
      "Epoch [120/900], Loss: 0.3085, 학습 정확도: 88.25%, 평가 정확도: 75.07%\n",
      "Epoch [121/900], Loss: 0.3016, 학습 정확도: 88.52%, 평가 정확도: 76.02%\n",
      "Epoch [122/900], Loss: 0.3011, 학습 정확도: 88.53%, 평가 정확도: 74.86%\n",
      "Epoch [123/900], Loss: 0.2999, 학습 정확도: 88.53%, 평가 정확도: 73.89%\n",
      "Epoch [124/900], Loss: 0.2965, 학습 정확도: 88.68%, 평가 정확도: 77.89%\n",
      "Epoch [125/900], Loss: 0.2963, 학습 정확도: 88.68%, 평가 정확도: 77.36%\n",
      "Epoch [126/900], Loss: 0.2957, 학습 정확도: 88.72%, 평가 정확도: 78.66%\n",
      "Epoch [127/900], Loss: 0.2933, 학습 정확도: 88.82%, 평가 정확도: 79.28%\n",
      "Epoch [128/900], Loss: 0.2911, 학습 정확도: 88.90%, 평가 정확도: 76.58%\n",
      "Epoch [129/900], Loss: 0.2922, 학습 정확도: 88.91%, 평가 정확도: 79.91%\n",
      "Epoch [130/900], Loss: 0.2896, 학습 정확도: 88.96%, 평가 정확도: 77.00%\n",
      "Epoch [131/900], Loss: 0.2893, 학습 정확도: 89.00%, 평가 정확도: 78.83%\n",
      "Epoch [132/900], Loss: 0.2869, 학습 정확도: 89.07%, 평가 정확도: 72.18%\n",
      "Epoch [133/900], Loss: 0.2854, 학습 정확도: 89.11%, 평가 정확도: 79.34%\n",
      "Epoch [134/900], Loss: 0.2831, 학습 정확도: 89.20%, 평가 정확도: 76.42%\n",
      "Epoch [135/900], Loss: 0.2854, 학습 정확도: 89.12%, 평가 정확도: 75.95%\n",
      "Epoch [136/900], Loss: 0.2812, 학습 정확도: 89.21%, 평가 정확도: 79.17%\n",
      "Epoch [137/900], Loss: 0.2781, 학습 정확도: 89.38%, 평가 정확도: 79.02%\n",
      "Epoch [138/900], Loss: 0.2757, 학습 정확도: 89.56%, 평가 정확도: 78.73%\n",
      "Epoch [139/900], Loss: 0.2751, 학습 정확도: 89.52%, 평가 정확도: 74.27%\n",
      "Epoch [140/900], Loss: 0.2757, 학습 정확도: 89.57%, 평가 정확도: 78.78%\n",
      "Epoch [141/900], Loss: 0.2733, 학습 정확도: 89.65%, 평가 정확도: 77.61%\n",
      "Epoch [142/900], Loss: 0.2739, 학습 정확도: 89.63%, 평가 정확도: 77.79%\n",
      "Epoch [143/900], Loss: 0.2746, 학습 정확도: 89.53%, 평가 정확도: 79.12%\n",
      "Epoch [144/900], Loss: 0.2716, 학습 정확도: 89.67%, 평가 정확도: 78.03%\n",
      "Epoch [145/900], Loss: 0.2715, 학습 정확도: 89.71%, 평가 정확도: 77.53%\n",
      "Epoch [146/900], Loss: 0.2707, 학습 정확도: 89.77%, 평가 정확도: 76.92%\n",
      "Epoch [147/900], Loss: 0.2694, 학습 정확도: 89.74%, 평가 정확도: 80.66%\n",
      "Epoch [148/900], Loss: 0.2697, 학습 정확도: 89.72%, 평가 정확도: 76.30%\n",
      "Epoch [149/900], Loss: 0.2708, 학습 정확도: 89.74%, 평가 정확도: 78.20%\n",
      "Epoch [150/900], Loss: 0.2678, 학습 정확도: 89.82%, 평가 정확도: 77.17%\n",
      "Epoch [151/900], Loss: 0.2637, 학습 정확도: 90.00%, 평가 정확도: 80.91%\n",
      "Epoch [152/900], Loss: 0.2620, 학습 정확도: 90.00%, 평가 정확도: 80.39%\n",
      "Epoch [153/900], Loss: 0.2606, 학습 정확도: 90.07%, 평가 정확도: 78.93%\n",
      "Epoch [154/900], Loss: 0.2618, 학습 정확도: 90.12%, 평가 정확도: 76.54%\n",
      "Epoch [155/900], Loss: 0.2601, 학습 정확도: 90.12%, 평가 정확도: 76.38%\n",
      "Epoch [156/900], Loss: 0.2614, 학습 정확도: 90.08%, 평가 정확도: 79.67%\n",
      "Epoch [157/900], Loss: 0.2583, 학습 정확도: 90.24%, 평가 정확도: 79.37%\n",
      "Epoch [158/900], Loss: 0.2559, 학습 정확도: 90.30%, 평가 정확도: 80.36%\n",
      "Epoch [159/900], Loss: 0.2580, 학습 정확도: 90.26%, 평가 정확도: 80.11%\n",
      "Epoch [160/900], Loss: 0.2575, 학습 정확도: 90.29%, 평가 정확도: 79.34%\n",
      "Epoch [161/900], Loss: 0.2562, 학습 정확도: 90.30%, 평가 정확도: 79.43%\n",
      "Epoch [162/900], Loss: 0.2565, 학습 정확도: 90.26%, 평가 정확도: 78.86%\n",
      "Epoch [163/900], Loss: 0.2537, 학습 정확도: 90.37%, 평가 정확도: 80.33%\n",
      "Epoch [164/900], Loss: 0.2540, 학습 정확도: 90.33%, 평가 정확도: 81.02%\n",
      "Epoch [165/900], Loss: 0.2545, 학습 정확도: 90.33%, 평가 정확도: 81.25%\n",
      "Epoch [166/900], Loss: 0.2511, 학습 정확도: 90.43%, 평가 정확도: 80.57%\n",
      "Epoch [167/900], Loss: 0.2517, 학습 정확도: 90.50%, 평가 정확도: 79.84%\n",
      "Epoch [168/900], Loss: 0.2489, 학습 정확도: 90.52%, 평가 정확도: 80.39%\n",
      "Epoch [169/900], Loss: 0.2473, 학습 정확도: 90.64%, 평가 정확도: 79.59%\n",
      "Epoch [170/900], Loss: 0.2484, 학습 정확도: 90.58%, 평가 정확도: 79.58%\n",
      "Epoch [171/900], Loss: 0.2484, 학습 정확도: 90.72%, 평가 정확도: 81.39%\n",
      "Epoch [172/900], Loss: 0.2462, 학습 정확도: 90.73%, 평가 정확도: 79.91%\n",
      "Epoch [173/900], Loss: 0.2464, 학습 정확도: 90.69%, 평가 정확도: 79.72%\n",
      "Epoch [174/900], Loss: 0.2475, 학습 정확도: 90.65%, 평가 정확도: 81.20%\n",
      "Epoch [175/900], Loss: 0.2461, 학습 정확도: 90.66%, 평가 정확도: 79.84%\n",
      "Epoch [176/900], Loss: 0.2463, 학습 정확도: 90.63%, 평가 정확도: 80.61%\n",
      "Epoch [177/900], Loss: 0.2447, 학습 정확도: 90.69%, 평가 정확도: 77.41%\n",
      "Epoch [178/900], Loss: 0.2433, 학습 정확도: 90.72%, 평가 정확도: 79.68%\n",
      "Epoch [179/900], Loss: 0.2429, 학습 정확도: 90.80%, 평가 정확도: 81.36%\n",
      "Epoch [180/900], Loss: 0.2432, 학습 정확도: 90.78%, 평가 정확도: 80.07%\n",
      "Epoch [181/900], Loss: 0.2403, 학습 정확도: 90.87%, 평가 정확도: 81.70%\n",
      "Epoch [182/900], Loss: 0.2407, 학습 정확도: 90.92%, 평가 정확도: 81.52%\n",
      "Epoch [183/900], Loss: 0.2416, 학습 정확도: 90.90%, 평가 정확도: 80.55%\n",
      "Epoch [184/900], Loss: 0.2390, 학습 정확도: 90.97%, 평가 정확도: 79.92%\n",
      "Epoch [185/900], Loss: 0.2411, 학습 정확도: 90.84%, 평가 정확도: 80.47%\n",
      "Epoch [186/900], Loss: 0.2382, 학습 정확도: 90.95%, 평가 정확도: 81.48%\n",
      "Epoch [187/900], Loss: 0.2388, 학습 정확도: 91.02%, 평가 정확도: 80.94%\n",
      "Epoch [188/900], Loss: 0.2366, 학습 정확도: 91.07%, 평가 정확도: 81.11%\n",
      "Epoch [189/900], Loss: 0.2392, 학습 정확도: 90.96%, 평가 정확도: 81.31%\n",
      "Epoch [190/900], Loss: 0.2376, 학습 정확도: 90.98%, 평가 정확도: 79.87%\n",
      "Epoch [191/900], Loss: 0.2349, 학습 정확도: 91.14%, 평가 정확도: 81.72%\n",
      "Epoch [192/900], Loss: 0.2373, 학습 정확도: 91.03%, 평가 정확도: 81.77%\n",
      "Epoch [193/900], Loss: 0.2365, 학습 정확도: 91.08%, 평가 정확도: 81.03%\n",
      "Epoch [194/900], Loss: 0.2363, 학습 정확도: 91.09%, 평가 정확도: 81.75%\n",
      "Epoch [195/900], Loss: 0.2346, 학습 정확도: 91.15%, 평가 정확도: 81.98%\n",
      "Epoch [196/900], Loss: 0.2323, 학습 정확도: 91.28%, 평가 정확도: 81.66%\n",
      "Epoch [197/900], Loss: 0.2333, 학습 정확도: 91.20%, 평가 정확도: 81.72%\n",
      "Epoch [198/900], Loss: 0.2325, 학습 정확도: 91.23%, 평가 정확도: 81.53%\n",
      "Epoch [199/900], Loss: 0.2325, 학습 정확도: 91.21%, 평가 정확도: 81.61%\n",
      "Epoch [200/900], Loss: 0.2330, 학습 정확도: 91.23%, 평가 정확도: 81.86%\n",
      "Epoch [201/900], Loss: 0.2328, 학습 정확도: 91.23%, 평가 정확도: 81.94%\n",
      "Epoch [202/900], Loss: 0.2323, 학습 정확도: 91.29%, 평가 정확도: 82.00%\n",
      "Epoch [203/900], Loss: 0.2312, 학습 정확도: 91.26%, 평가 정확도: 81.22%\n",
      "Epoch [204/900], Loss: 0.2293, 학습 정확도: 91.37%, 평가 정확도: 81.71%\n",
      "Epoch [205/900], Loss: 0.2326, 학습 정확도: 91.16%, 평가 정확도: 80.80%\n",
      "Epoch [206/900], Loss: 0.2306, 학습 정확도: 91.28%, 평가 정확도: 81.81%\n",
      "Epoch [207/900], Loss: 0.2311, 학습 정확도: 91.24%, 평가 정확도: 80.98%\n",
      "Epoch [208/900], Loss: 0.2283, 학습 정확도: 91.36%, 평가 정확도: 81.66%\n",
      "Epoch [209/900], Loss: 0.2297, 학습 정확도: 91.28%, 평가 정확도: 82.14%\n",
      "Epoch [210/900], Loss: 0.2288, 학습 정확도: 91.40%, 평가 정확도: 81.38%\n",
      "Epoch [211/900], Loss: 0.2267, 학습 정확도: 91.51%, 평가 정확도: 81.55%\n",
      "Epoch [212/900], Loss: 0.2291, 학습 정확도: 91.36%, 평가 정확도: 80.78%\n",
      "Epoch [213/900], Loss: 0.2259, 학습 정확도: 91.50%, 평가 정확도: 82.16%\n",
      "Epoch [214/900], Loss: 0.2274, 학습 정확도: 91.37%, 평가 정확도: 81.83%\n",
      "Epoch [215/900], Loss: 0.2246, 학습 정확도: 91.49%, 평가 정확도: 81.59%\n",
      "Epoch [216/900], Loss: 0.2249, 학습 정확도: 91.51%, 평가 정확도: 81.43%\n",
      "Epoch [217/900], Loss: 0.2272, 학습 정확도: 91.43%, 평가 정확도: 81.50%\n",
      "Epoch [218/900], Loss: 0.2270, 학습 정확도: 91.42%, 평가 정확도: 81.88%\n",
      "Epoch [219/900], Loss: 0.2245, 학습 정확도: 91.49%, 평가 정확도: 82.11%\n",
      "Epoch [220/900], Loss: 0.2239, 학습 정확도: 91.49%, 평가 정확도: 82.00%\n",
      "Epoch [221/900], Loss: 0.2234, 학습 정확도: 91.55%, 평가 정확도: 81.39%\n",
      "Epoch [222/900], Loss: 0.2225, 학습 정확도: 91.67%, 평가 정확도: 82.06%\n",
      "Epoch [223/900], Loss: 0.2247, 학습 정확도: 91.52%, 평가 정확도: 81.22%\n",
      "Epoch [224/900], Loss: 0.2276, 학습 정확도: 91.33%, 평가 정확도: 81.14%\n",
      "Epoch [225/900], Loss: 0.2237, 학습 정확도: 91.52%, 평가 정확도: 82.03%\n",
      "Epoch [226/900], Loss: 0.2207, 학습 정확도: 91.69%, 평가 정확도: 81.94%\n",
      "Epoch [227/900], Loss: 0.2206, 학습 정확도: 91.69%, 평가 정확도: 81.77%\n",
      "Epoch [228/900], Loss: 0.2233, 학습 정확도: 91.60%, 평가 정확도: 81.83%\n",
      "Epoch [229/900], Loss: 0.2204, 학습 정확도: 91.62%, 평가 정확도: 81.70%\n",
      "Epoch [230/900], Loss: 0.2206, 학습 정확도: 91.61%, 평가 정확도: 81.30%\n",
      "Epoch [231/900], Loss: 0.2208, 학습 정확도: 91.70%, 평가 정확도: 82.09%\n",
      "Epoch [232/900], Loss: 0.2198, 학습 정확도: 91.72%, 평가 정확도: 82.17%\n",
      "Epoch [233/900], Loss: 0.2218, 학습 정확도: 91.64%, 평가 정확도: 82.17%\n",
      "Epoch [234/900], Loss: 0.2204, 학습 정확도: 91.72%, 평가 정확도: 82.14%\n",
      "Epoch [235/900], Loss: 0.2210, 학습 정확도: 91.70%, 평가 정확도: 82.36%\n",
      "Epoch [236/900], Loss: 0.2201, 학습 정확도: 91.66%, 평가 정확도: 81.90%\n",
      "Epoch [237/900], Loss: 0.2217, 학습 정확도: 91.54%, 평가 정확도: 82.19%\n",
      "Epoch [238/900], Loss: 0.2195, 학습 정확도: 91.72%, 평가 정확도: 81.92%\n",
      "Epoch [239/900], Loss: 0.2188, 학습 정확도: 91.74%, 평가 정확도: 81.73%\n",
      "Epoch [240/900], Loss: 0.2197, 학습 정확도: 91.70%, 평가 정확도: 82.16%\n",
      "Epoch [241/900], Loss: 0.2176, 학습 정확도: 91.80%, 평가 정확도: 82.31%\n",
      "Epoch [242/900], Loss: 0.2175, 학습 정확도: 91.81%, 평가 정확도: 81.90%\n",
      "Epoch [243/900], Loss: 0.2177, 학습 정확도: 91.78%, 평가 정확도: 82.12%\n",
      "Epoch [244/900], Loss: 0.2178, 학습 정확도: 91.79%, 평가 정확도: 82.12%\n",
      "Epoch [245/900], Loss: 0.2186, 학습 정확도: 91.76%, 평가 정확도: 82.23%\n",
      "Epoch [246/900], Loss: 0.2173, 학습 정확도: 91.85%, 평가 정확도: 82.16%\n",
      "Epoch [247/900], Loss: 0.2165, 학습 정확도: 91.83%, 평가 정확도: 82.17%\n",
      "Epoch [248/900], Loss: 0.2156, 학습 정확도: 91.84%, 평가 정확도: 82.18%\n",
      "Epoch [249/900], Loss: 0.2167, 학습 정확도: 91.84%, 평가 정확도: 81.94%\n",
      "Epoch [250/900], Loss: 0.2169, 학습 정확도: 91.88%, 평가 정확도: 82.16%\n",
      "Epoch [251/900], Loss: 0.2174, 학습 정확도: 91.81%, 평가 정확도: 82.17%\n",
      "Epoch [252/900], Loss: 0.2151, 학습 정확도: 91.87%, 평가 정확도: 82.23%\n",
      "Epoch [253/900], Loss: 0.2186, 학습 정확도: 91.80%, 평가 정확도: 82.11%\n",
      "Epoch [254/900], Loss: 0.2149, 학습 정확도: 91.91%, 평가 정확도: 81.80%\n",
      "Epoch [255/900], Loss: 0.2171, 학습 정확도: 91.76%, 평가 정확도: 82.27%\n",
      "Epoch [256/900], Loss: 0.2160, 학습 정확도: 91.84%, 평가 정확도: 81.94%\n",
      "Epoch [257/900], Loss: 0.2163, 학습 정확도: 91.80%, 평가 정확도: 82.12%\n",
      "Epoch [258/900], Loss: 0.2146, 학습 정확도: 91.91%, 평가 정확도: 82.45%\n",
      "Epoch [259/900], Loss: 0.2137, 학습 정확도: 91.87%, 평가 정확도: 82.27%\n",
      "Epoch [260/900], Loss: 0.2136, 학습 정확도: 91.99%, 평가 정확도: 82.37%\n",
      "Epoch [261/900], Loss: 0.2157, 학습 정확도: 91.88%, 평가 정확도: 82.05%\n",
      "Epoch [262/900], Loss: 0.2157, 학습 정확도: 91.88%, 평가 정확도: 82.21%\n",
      "Epoch [263/900], Loss: 0.2158, 학습 정확도: 91.82%, 평가 정확도: 82.15%\n",
      "Epoch [264/900], Loss: 0.2156, 학습 정확도: 91.81%, 평가 정확도: 82.20%\n",
      "Epoch [265/900], Loss: 0.2150, 학습 정확도: 91.88%, 평가 정확도: 82.13%\n",
      "Epoch [266/900], Loss: 0.2133, 학습 정확도: 91.96%, 평가 정확도: 82.14%\n",
      "Epoch [267/900], Loss: 0.2131, 학습 정확도: 91.94%, 평가 정확도: 82.03%\n",
      "Epoch [268/900], Loss: 0.2135, 학습 정확도: 91.91%, 평가 정확도: 81.85%\n",
      "Epoch [269/900], Loss: 0.2164, 학습 정확도: 91.86%, 평가 정확도: 82.35%\n",
      "Epoch [270/900], Loss: 0.2145, 학습 정확도: 91.93%, 평가 정확도: 82.28%\n",
      "Epoch [271/900], Loss: 0.2121, 학습 정확도: 92.00%, 평가 정확도: 82.25%\n",
      "Epoch [272/900], Loss: 0.2135, 학습 정확도: 91.90%, 평가 정확도: 82.19%\n",
      "Epoch [273/900], Loss: 0.2131, 학습 정확도: 91.95%, 평가 정확도: 82.29%\n",
      "Epoch [274/900], Loss: 0.2122, 학습 정확도: 91.97%, 평가 정확도: 82.31%\n",
      "Epoch [275/900], Loss: 0.2154, 학습 정확도: 91.87%, 평가 정확도: 82.31%\n",
      "Epoch [276/900], Loss: 0.2130, 학습 정확도: 91.94%, 평가 정확도: 82.31%\n",
      "Epoch [277/900], Loss: 0.2128, 학습 정확도: 91.92%, 평가 정확도: 82.18%\n",
      "Epoch [278/900], Loss: 0.2123, 학습 정확도: 92.02%, 평가 정확도: 82.19%\n",
      "Epoch [279/900], Loss: 0.2125, 학습 정확도: 92.04%, 평가 정확도: 82.45%\n",
      "Epoch [280/900], Loss: 0.2126, 학습 정확도: 91.93%, 평가 정확도: 82.19%\n",
      "Epoch [281/900], Loss: 0.2103, 학습 정확도: 92.00%, 평가 정확도: 82.12%\n",
      "Epoch [282/900], Loss: 0.2105, 학습 정확도: 92.03%, 평가 정확도: 82.36%\n",
      "Epoch [283/900], Loss: 0.2135, 학습 정확도: 91.86%, 평가 정확도: 82.26%\n",
      "Epoch [284/900], Loss: 0.2105, 학습 정확도: 92.01%, 평가 정확도: 82.16%\n",
      "Epoch [285/900], Loss: 0.2109, 학습 정확도: 92.02%, 평가 정확도: 82.07%\n",
      "Epoch [286/900], Loss: 0.2118, 학습 정확도: 92.01%, 평가 정확도: 82.22%\n",
      "Epoch [287/900], Loss: 0.2109, 학습 정확도: 92.09%, 평가 정확도: 82.25%\n",
      "Epoch [288/900], Loss: 0.2098, 학습 정확도: 92.05%, 평가 정확도: 82.25%\n",
      "Epoch [289/900], Loss: 0.2115, 학습 정확도: 92.03%, 평가 정확도: 82.00%\n",
      "Epoch [290/900], Loss: 0.2109, 학습 정확도: 92.01%, 평가 정확도: 82.30%\n",
      "Epoch [291/900], Loss: 0.2087, 학습 정확도: 92.11%, 평가 정확도: 82.22%\n",
      "Epoch [292/900], Loss: 0.2106, 학습 정확도: 92.01%, 평가 정확도: 82.16%\n",
      "Epoch [293/900], Loss: 0.2092, 학습 정확도: 92.15%, 평가 정확도: 82.19%\n",
      "Epoch [294/900], Loss: 0.2099, 학습 정확도: 92.05%, 평가 정확도: 82.10%\n",
      "Epoch [295/900], Loss: 0.2116, 학습 정확도: 91.96%, 평가 정확도: 82.44%\n",
      "Epoch [296/900], Loss: 0.2113, 학습 정확도: 92.01%, 평가 정확도: 82.22%\n",
      "Epoch [297/900], Loss: 0.2083, 학습 정확도: 92.05%, 평가 정확도: 82.14%\n",
      "Epoch [298/900], Loss: 0.2095, 학습 정확도: 92.04%, 평가 정확도: 82.31%\n",
      "Epoch [299/900], Loss: 0.2114, 학습 정확도: 92.03%, 평가 정확도: 82.23%\n",
      "Epoch [300/900], Loss: 0.2101, 학습 정확도: 92.07%, 평가 정확도: 82.29%\n",
      "Epoch [301/900], Loss: 0.2111, 학습 정확도: 92.02%, 평가 정확도: 82.41%\n",
      "Epoch [302/900], Loss: 0.2110, 학습 정확도: 92.03%, 평가 정확도: 82.29%\n",
      "Epoch [303/900], Loss: 0.2101, 학습 정확도: 92.03%, 평가 정확도: 82.36%\n",
      "Epoch [304/900], Loss: 0.2079, 학습 정확도: 92.10%, 평가 정확도: 82.34%\n",
      "Epoch [305/900], Loss: 0.2077, 학습 정확도: 92.14%, 평가 정확도: 82.39%\n",
      "Epoch [306/900], Loss: 0.2086, 학습 정확도: 92.11%, 평가 정확도: 82.33%\n",
      "Epoch [307/900], Loss: 0.2099, 학습 정확도: 92.05%, 평가 정확도: 82.36%\n",
      "Epoch [308/900], Loss: 0.2095, 학습 정확도: 92.08%, 평가 정확도: 82.27%\n",
      "Epoch [309/900], Loss: 0.2084, 학습 정확도: 92.16%, 평가 정확도: 82.21%\n",
      "Epoch [310/900], Loss: 0.2089, 학습 정확도: 92.12%, 평가 정확도: 82.34%\n",
      "Epoch [311/900], Loss: 0.2080, 학습 정확도: 92.18%, 평가 정확도: 82.27%\n",
      "Epoch [312/900], Loss: 0.2076, 학습 정확도: 92.10%, 평가 정확도: 82.50%\n",
      "Epoch [313/900], Loss: 0.2088, 학습 정확도: 92.11%, 평가 정확도: 82.26%\n",
      "Epoch [314/900], Loss: 0.2081, 학습 정확도: 92.10%, 평가 정확도: 82.31%\n",
      "Epoch [315/900], Loss: 0.2078, 학습 정확도: 92.15%, 평가 정확도: 82.19%\n",
      "Epoch [316/900], Loss: 0.2084, 학습 정확도: 92.14%, 평가 정확도: 82.41%\n",
      "Epoch [317/900], Loss: 0.2074, 학습 정확도: 92.21%, 평가 정확도: 82.21%\n",
      "Epoch [318/900], Loss: 0.2078, 학습 정확도: 92.09%, 평가 정확도: 82.44%\n",
      "Epoch [319/900], Loss: 0.2081, 학습 정확도: 92.16%, 평가 정확도: 82.37%\n",
      "Epoch [320/900], Loss: 0.2061, 학습 정확도: 92.24%, 평가 정확도: 82.25%\n",
      "Epoch [321/900], Loss: 0.2080, 학습 정확도: 92.21%, 평가 정확도: 82.38%\n",
      "Epoch [322/900], Loss: 0.2060, 학습 정확도: 92.10%, 평가 정확도: 82.30%\n",
      "Epoch [323/900], Loss: 0.2063, 학습 정확도: 92.20%, 평가 정확도: 82.22%\n",
      "Epoch [324/900], Loss: 0.2073, 학습 정확도: 92.17%, 평가 정확도: 82.16%\n",
      "Epoch [325/900], Loss: 0.2068, 학습 정확도: 92.12%, 평가 정확도: 82.45%\n",
      "Epoch [326/900], Loss: 0.2072, 학습 정확도: 92.14%, 평가 정확도: 82.41%\n",
      "Epoch [327/900], Loss: 0.2107, 학습 정확도: 92.06%, 평가 정확도: 82.36%\n",
      "Epoch [328/900], Loss: 0.2093, 학습 정확도: 92.01%, 평가 정확도: 82.39%\n",
      "Epoch [329/900], Loss: 0.2088, 학습 정확도: 92.07%, 평가 정확도: 82.47%\n",
      "Epoch [330/900], Loss: 0.2050, 학습 정확도: 92.27%, 평가 정확도: 82.43%\n",
      "Epoch [331/900], Loss: 0.2058, 학습 정확도: 92.22%, 평가 정확도: 82.25%\n",
      "Epoch [332/900], Loss: 0.2078, 학습 정확도: 92.20%, 평가 정확도: 82.33%\n",
      "Epoch [333/900], Loss: 0.2060, 학습 정확도: 92.19%, 평가 정확도: 82.28%\n",
      "Epoch [334/900], Loss: 0.2068, 학습 정확도: 92.21%, 평가 정확도: 82.34%\n",
      "Epoch [335/900], Loss: 0.2066, 학습 정확도: 92.24%, 평가 정확도: 82.39%\n",
      "Epoch [336/900], Loss: 0.2065, 학습 정확도: 92.22%, 평가 정확도: 82.39%\n",
      "Epoch [337/900], Loss: 0.2074, 학습 정확도: 92.22%, 평가 정확도: 82.31%\n",
      "Epoch [338/900], Loss: 0.2076, 학습 정확도: 92.15%, 평가 정확도: 82.33%\n",
      "Epoch [339/900], Loss: 0.2074, 학습 정확도: 92.15%, 평가 정확도: 82.39%\n",
      "Epoch [340/900], Loss: 0.2056, 학습 정확도: 92.25%, 평가 정확도: 82.34%\n",
      "Epoch [341/900], Loss: 0.2074, 학습 정확도: 92.16%, 평가 정확도: 82.30%\n",
      "Epoch [342/900], Loss: 0.2087, 학습 정확도: 92.13%, 평가 정확도: 82.34%\n",
      "Epoch [343/900], Loss: 0.2077, 학습 정확도: 92.18%, 평가 정확도: 82.48%\n",
      "Epoch [344/900], Loss: 0.2073, 학습 정확도: 92.21%, 평가 정확도: 82.29%\n",
      "Epoch [345/900], Loss: 0.2073, 학습 정확도: 92.13%, 평가 정확도: 82.34%\n",
      "Epoch [346/900], Loss: 0.2053, 학습 정확도: 92.25%, 평가 정확도: 82.44%\n",
      "Epoch [347/900], Loss: 0.2070, 학습 정확도: 92.14%, 평가 정확도: 82.33%\n",
      "Epoch [348/900], Loss: 0.2054, 학습 정확도: 92.27%, 평가 정확도: 82.42%\n",
      "Epoch [349/900], Loss: 0.2051, 학습 정확도: 92.26%, 평가 정확도: 82.37%\n",
      "Epoch [350/900], Loss: 0.2043, 학습 정확도: 92.29%, 평가 정확도: 82.45%\n",
      "Epoch [351/900], Loss: 0.2063, 학습 정확도: 92.16%, 평가 정확도: 82.36%\n",
      "Epoch [352/900], Loss: 0.2067, 학습 정확도: 92.14%, 평가 정확도: 82.36%\n",
      "Epoch [353/900], Loss: 0.2060, 학습 정확도: 92.20%, 평가 정확도: 82.47%\n",
      "Epoch [354/900], Loss: 0.2062, 학습 정확도: 92.18%, 평가 정확도: 82.30%\n",
      "Epoch [355/900], Loss: 0.2058, 학습 정확도: 92.20%, 평가 정확도: 82.35%\n",
      "Epoch [356/900], Loss: 0.2044, 학습 정확도: 92.22%, 평가 정확도: 82.19%\n",
      "Epoch [357/900], Loss: 0.2074, 학습 정확도: 92.19%, 평가 정확도: 82.39%\n",
      "Epoch [358/900], Loss: 0.2079, 학습 정확도: 92.19%, 평가 정확도: 82.33%\n",
      "Epoch [359/900], Loss: 0.2059, 학습 정확도: 92.19%, 평가 정확도: 82.43%\n",
      "Epoch [360/900], Loss: 0.2053, 학습 정확도: 92.25%, 평가 정확도: 82.38%\n",
      "Epoch [361/900], Loss: 0.2055, 학습 정확도: 92.20%, 평가 정확도: 82.24%\n",
      "Epoch [362/900], Loss: 0.2072, 학습 정확도: 92.15%, 평가 정확도: 82.35%\n",
      "Epoch [363/900], Loss: 0.2045, 학습 정확도: 92.31%, 평가 정확도: 82.41%\n",
      "Epoch [364/900], Loss: 0.2052, 학습 정확도: 92.27%, 평가 정확도: 82.42%\n",
      "Epoch [365/900], Loss: 0.2068, 학습 정확도: 92.13%, 평가 정확도: 82.45%\n",
      "Epoch [366/900], Loss: 0.2067, 학습 정확도: 92.20%, 평가 정확도: 82.49%\n",
      "Epoch [367/900], Loss: 0.2052, 학습 정확도: 92.22%, 평가 정확도: 82.34%\n",
      "Epoch [368/900], Loss: 0.2044, 학습 정확도: 92.28%, 평가 정확도: 82.39%\n",
      "Epoch [369/900], Loss: 0.2058, 학습 정확도: 92.28%, 평가 정확도: 82.47%\n",
      "Epoch [370/900], Loss: 0.2053, 학습 정확도: 92.20%, 평가 정확도: 82.47%\n",
      "Epoch [371/900], Loss: 0.2071, 학습 정확도: 92.21%, 평가 정확도: 82.39%\n",
      "Epoch [372/900], Loss: 0.2063, 학습 정확도: 92.21%, 평가 정확도: 82.40%\n",
      "Early stopping triggered!\n",
      "Early Stopping triggered at epoch 312, Best 평가 정확도: 82.50%, Best 학습 정확도: 92.10%\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "97533fa5ca9efa67"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
